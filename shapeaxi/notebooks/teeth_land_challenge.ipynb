{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/famli_netapp_shared/C1_ML_Analysis/src/ShapeAXI/')\n",
    "import torch\n",
    "from torch import nn\n",
    "import shapeaxi\n",
    "from shapeaxi import utils\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.structures import (Meshes, Pointclouds)\n",
    "import json\n",
    "import random\n",
    "\n",
    "from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\n",
    "\n",
    "from pytorch3d.renderer import (\n",
    "    TexturesVertex\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pointcloud(mesh, title=\"\", n_points=5000):\n",
    "    points = sample_points_from_meshes(mesh, n_points)\n",
    "    # points = mesh.verts_packed()\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, mode='markers', marker=dict(\n",
    "        size=2,\n",
    "        color=z,                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=0.8\n",
    "    ))])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mount_point = '/mnt/raid/home/jprieto/3DTeethSeg'\n",
    "\n",
    "surf = utils.ReadSurf(f'{mount_point}/lower/GSHA8E4C/GSHA8E4C_lower.obj')\n",
    "labels = json.loads(open(f'{mount_point}/lower/GSHA8E4C/GSHA8E4C_lower.json').read())\n",
    "landmarks = json.loads(open(f'{mount_point}/Batch_2_4_23_24/GSHA8E4C_lower__kpt.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_color():\n",
    "    return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "def assign_random_colors(labels):\n",
    "    unique_labels = set(labels)\n",
    "    color_map = {label: generate_random_color() for label in unique_labels}\n",
    "    return color_map\n",
    "\n",
    "color_mapping_mesh = assign_random_colors(labels[\"labels\"])\n",
    "\n",
    "colors_mesh = [color_mapping_mesh[label] for label in labels[\"labels\"]]\n",
    "\n",
    "color_mapping_landmarks = assign_random_colors([obj[\"key\"] for obj in landmarks[\"objects\"]])\n",
    "colors_landmarks = [color_mapping_landmarks[obj[\"key\"]] for obj in landmarks[\"objects\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, F = utils.PolyDataToTensors_v_f(surf)\n",
    "textures = TexturesVertex(torch.tensor(colors_mesh).unsqueeze(0).to(torch.float)/255.0)\n",
    "mesh = Meshes(verts=V.unsqueeze(0), faces=F.unsqueeze(0), textures=textures)\n",
    "\n",
    "landmarks_coords = torch.tensor([obj[\"coord\"] for obj in landmarks[\"objects\"]])\n",
    "landmarks_pc = Pointclouds(points=landmarks_coords.unsqueeze(0), features=torch.tensor(colors_landmarks).unsqueeze(0).to(torch.float)/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scene({\n",
    "    \"Dental Challenge\": {\n",
    "        \"dental\": mesh,\n",
    "        \"landmarks\": landmarks_pc\n",
    "    }\n",
    "}, pointcloud_marker_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pointcloud(mesh, n_points=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ocnn\n",
    "from ocnn.octree import Octree, Points\n",
    "\n",
    "class Transform:\n",
    "  def __init__(self, depth: int, full_depth: int, distort: bool, angle: list,\n",
    "               interval: list, scale: float, uniform: bool, jitter: float,\n",
    "               flip: list, orient_normal: str = '', **kwargs):\n",
    "    super().__init__()\n",
    "\n",
    "    # for octree building\n",
    "    self.depth = depth\n",
    "    self.full_depth = full_depth\n",
    "\n",
    "    # for data augmentation\n",
    "    self.distort = distort\n",
    "    self.angle = angle\n",
    "    self.interval = interval\n",
    "    self.scale = scale\n",
    "    self.uniform = uniform\n",
    "    self.jitter = jitter\n",
    "    self.flip = flip\n",
    "\n",
    "    # for other transformations\n",
    "    self.orient_normal = orient_normal\n",
    "\n",
    "  def __call__(self, sample: dict, idx: int):\n",
    "    r''''''\n",
    "\n",
    "    output = self.preprocess(sample, idx)\n",
    "    output = self.transform(output, idx)\n",
    "    output['octree'] = self.points2octree(output['points'])\n",
    "    return output\n",
    "\n",
    "  def preprocess(self, sample: dict, idx: int):\n",
    "    r''' Transforms :attr:`sample` to :class:`Points` and performs some specific\n",
    "    transformations, like normalization.\n",
    "    '''\n",
    "\n",
    "    xyz = torch.from_numpy(sample.pop('points'))\n",
    "    normals = torch.from_numpy(sample.pop('normals'))\n",
    "    sample['points'] = Points(xyz, normals)\n",
    "    return sample\n",
    "\n",
    "  def transform(self, sample: dict, idx: int):\n",
    "    r''' Applies the general transformations provided by :obj:`ocnn`.\n",
    "    '''\n",
    "\n",
    "    # The augmentations including rotation, scaling, and jittering.\n",
    "    points = sample['points']\n",
    "    if self.distort:\n",
    "      rng_angle, rng_scale, rng_jitter, rnd_flip = self.rnd_parameters()\n",
    "      points.flip(rnd_flip)\n",
    "      points.rotate(rng_angle)\n",
    "      points.translate(rng_jitter)\n",
    "      points.scale(rng_scale)\n",
    "\n",
    "    if self.orient_normal:\n",
    "      points.orient_normal(self.orient_normal)\n",
    "\n",
    "    # !!! NOTE: Clip the point cloud to [-1, 1] before building the octree\n",
    "    inbox_mask = points.clip(min=-1, max=1)\n",
    "    sample.update({'points': points, 'inbox_mask': inbox_mask})\n",
    "    return sample\n",
    "\n",
    "  def points2octree(self, points: Points):\n",
    "    r''' Converts the input :attr:`points` to an octree.\n",
    "    '''\n",
    "\n",
    "    octree = Octree(self.depth, self.full_depth)\n",
    "    octree.build_octree(points)\n",
    "    return octree\n",
    "\n",
    "  def rnd_parameters(self):\n",
    "    r''' Generates random parameters for data augmentation.\n",
    "    '''\n",
    "\n",
    "    rnd_angle = [None] * 3\n",
    "    for i in range(3):\n",
    "      rot_num = self.angle[i] // self.interval[i]\n",
    "      rnd = torch.randint(low=-rot_num, high=rot_num+1, size=(1,))\n",
    "      rnd_angle[i] = rnd * self.interval[i] * (3.14159265 / 180.0)\n",
    "    rnd_angle = torch.cat(rnd_angle)\n",
    "\n",
    "    rnd_scale = torch.rand(3) * (2 * self.scale) - self.scale + 1.0\n",
    "    if self.uniform:\n",
    "      rnd_scale[1] = rnd_scale[0]\n",
    "      rnd_scale[2] = rnd_scale[0]\n",
    "\n",
    "    rnd_flip = ''\n",
    "    for i, c in enumerate('xyz'):\n",
    "      if torch.rand([1]) < self.flip[i]:\n",
    "        rnd_flip = rnd_flip + c\n",
    "\n",
    "    rnd_jitter = torch.rand(3) * (2 * self.jitter) - self.jitter\n",
    "    return rnd_angle, rnd_scale, rnd_jitter, rnd_flip\n",
    "\n",
    "\n",
    "class CollateBatch:\n",
    "  r''' Merge a list of octrees and points into a batch.\n",
    "  '''\n",
    "\n",
    "  def __init__(self, merge_points: bool = False):\n",
    "    self.merge_points = merge_points\n",
    "\n",
    "  def __call__(self, batch: list):\n",
    "    assert type(batch) == list\n",
    "\n",
    "    outputs = {}\n",
    "    for key in batch[0].keys():\n",
    "      outputs[key] = [b[key] for b in batch]\n",
    "\n",
    "      # Merge a batch of octrees into one super octree\n",
    "      if 'octree' in key:\n",
    "        octree = ocnn.octree.merge_octrees(outputs[key])\n",
    "        # NOTE: remember to construct the neighbor indices\n",
    "        octree.construct_all_neigh()\n",
    "        outputs[key] = octree\n",
    "\n",
    "      # Merge a batch of points\n",
    "      if 'points' in key and self.merge_points:\n",
    "        outputs[key] = ocnn.octree.merge_points(outputs[key])\n",
    "\n",
    "      # Convert the labels to a Tensor\n",
    "      if 'label' in key:\n",
    "        outputs['label'] = torch.tensor(outputs[key])\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mount_point = \"/mnt/raid/home/jprieto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = utils.ReadSurf(f'{mount_point}/ModelNet40/airplane/train/airplane_0129.off')\n",
    "surf = utils.GetUnitSurf(surf)\n",
    "V, F = utils.PolyDataToTensors_v_f(surf)\n",
    "N = utils.GetNormalsTensor(surf)\n",
    "\n",
    "octree_0 = Octree(16)\n",
    "octree_0.build_octree(Points(V, normals=N))\n",
    "\n",
    "print(V.shape, N.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = utils.ReadSurf(f'{mount_point}/ModelNet40/airplane/test/airplane_0656.off')\n",
    "surf = utils.GetUnitSurf(surf)\n",
    "V, F = utils.PolyDataToTensors_v_f(surf)\n",
    "N = utils.GetNormalsTensor(surf)\n",
    "octree_1 = Octree(16)\n",
    "octree_1.build_octree(Points(V, normals=N))\n",
    "print(V.shape, N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octree = ocnn.octree.merge_octrees([octree_0, octree_1])\n",
    "# NOTE: remember to construct the neighbor indices\n",
    "octree.construct_all_neigh()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z, b = octree.xyzb(12)\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, mode='markers', marker=dict(\n",
    "        size=2,\n",
    "        color=z,                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=0.8\n",
    "    ))])\n",
    "fig.show()\n",
    "\n",
    "print(x.shape, y.shape, z.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ocnn.models.ResNet(in_channels=6, out_channels=1280, resblock_num=1, stages=3, nempty=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet(octree.get_input_feature('NP').to(torch.float), octree=octree, depth=16).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
