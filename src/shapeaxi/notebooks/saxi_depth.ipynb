{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.5' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/local/bin/python3.10 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch3d\n",
    "import sys\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from shapeaxi import saxi_nets\n",
    "from shapeaxi import saxi_dataset\n",
    "from shapeaxi import saxi_dataset\n",
    "from shapeaxi import saxi_transforms\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from pytorch3d.structures import Meshes \n",
    "from pytorch3d.renderer import (\n",
    "        FoVPerspectiveCameras, look_at_view_transform, look_at_rotation, \n",
    "        RasterizationSettings, MeshRenderer, MeshRasterizer, MeshRendererWithFragments, BlendParams,\n",
    "        SoftSilhouetteShader, HardPhongShader, SoftPhongShader, AmbientLights, PointLights, TexturesUV, TexturesVertex, TexturesAtlas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = saxi_nets.SaxiRingClassification(subdivision_level=3, out_classes=3, radius=1.1, hidden_dim=512, out_size=128, dropout_lvl=0.2, image_size=224, base_encoder=\"ViT\", base_encoder_params=\"in_channels=4, img_size=(224,224), patch_size=(16,16),spatial_dims=2\")\n",
    "model = saxi_nets.SaxiRingClassification(subdivision_level=2, out_classes=3, radius=1.05, hidden_dim=512, out_size=128, dropout_lvl=0.2, image_size=224, base_encoder=\"resnet18\", base_encoder_params=\"pretrained=False,spatial_dims=2,n_input_channels=4,num_classes=512\")\n",
    "model = model.to('cuda').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = saxi_dataset.SaxiDataset(pd.read_csv('/CMF/data/lumargot/DCBIA/Airway_Obst_Classif_Sample/airway_4classes_test.csv'), transform=saxi_transforms.EvalTransform(scale_factor=0.02764634543775486))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_figure(image_data1, image_data2):\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=('Image 1', 'Image 2'))\n",
    "\n",
    "    # Add initial frames for both images with shared coloraxis\n",
    "    fig.add_trace(go.Heatmap(z=image_data1[0], coloraxis=\"coloraxis\"), row=1, col=1)\n",
    "    fig.add_trace(go.Heatmap(z=image_data2[0], coloraxis=\"coloraxis\"), row=1, col=2)\n",
    "\n",
    "    # Create frames for the animation\n",
    "    frames = []\n",
    "    for k in range(image_data1.shape[0]):\n",
    "        frame = go.Frame(data=[\n",
    "            go.Heatmap(z=image_data1[k], coloraxis=\"coloraxis\"),\n",
    "            go.Heatmap(z=image_data2[k], coloraxis=\"coloraxis\")\n",
    "        ], name=str(k))\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Add frames to the figure\n",
    "    fig.frames = frames\n",
    "\n",
    "    # Calculate the aspect ratio\n",
    "    height, width = image_data1[0].shape[:2]\n",
    "    aspect_ratio = height / width\n",
    "\n",
    "    # Determine global min and max values for consistent color scale\n",
    "    vmin = min(image_data1.min(), image_data2.min())\n",
    "    vmax = max(image_data1.max(), image_data2.max())\n",
    "\n",
    "    # Update layout with animation settings and fixed aspect ratio\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1200,  # Adjust width as needed\n",
    "        height=600,  # Adjust height according to aspect ratio\n",
    "        coloraxis={\"colorscale\": \"jet\",\n",
    "                   \"cmin\": vmin,  # Set global min value for color scale\n",
    "                    \"cmax\": vmax},   # Set global max value for color scale},  # Set colorscale for the shared coloraxis\n",
    "        updatemenus=[{\n",
    "            \"buttons\": [\n",
    "                {\n",
    "                    \"args\": [None, {\"frame\": {\"duration\": 500, \"redraw\": True},\n",
    "                                    \"fromcurrent\": True, \"mode\": \"immediate\"}],\n",
    "                    \"label\": \"Play\",\n",
    "                    \"method\": \"animate\"\n",
    "                },\n",
    "                {\n",
    "                    \"args\": [[None], {\"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                                    \"mode\": \"immediate\"}],\n",
    "                    \"label\": \"Pause\",\n",
    "                    \"method\": \"animate\"\n",
    "                }\n",
    "            ],\n",
    "            \"direction\": \"left\",\n",
    "            \"pad\": {\"r\": 10, \"t\": 87},\n",
    "            \"showactive\": False,\n",
    "            \"type\": \"buttons\",\n",
    "            \"x\": 0.1,\n",
    "            \"xanchor\": \"right\",\n",
    "            \"y\": 0,\n",
    "            \"yanchor\": \"top\"\n",
    "        }],\n",
    "        sliders=[{\n",
    "            \"steps\": [\n",
    "                {\n",
    "                    \"args\": [[str(k)], {\"frame\": {\"duration\": 300, \"redraw\": True},\n",
    "                                        \"mode\": \"immediate\"}],\n",
    "                    \"label\": str(k),\n",
    "                    \"method\": \"animate\"\n",
    "                } for k in range(image_data1.shape[0])\n",
    "            ],\n",
    "            \"active\": 0,\n",
    "            \"yanchor\": \"top\",\n",
    "            \"xanchor\": \"left\",\n",
    "            \"currentvalue\": {\n",
    "                \"font\": {\"size\": 20},\n",
    "                \"prefix\": \"Frame:\",\n",
    "                \"visible\": True,\n",
    "                \"xanchor\": \"right\"\n",
    "            },\n",
    "            \"transition\": {\"duration\": 300, \"easing\": \"cubic-in-out\"}\n",
    "        }]\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def render(self, V, F, CN):\n",
    "    # Render the input surface mesh to an image\n",
    "    textures = TexturesVertex(verts_features=CN)\n",
    "    meshes = Meshes(verts=V, faces=F, textures=textures)\n",
    "    X = []\n",
    "    PF = []\n",
    "\n",
    "    for camera_position in self.ico_verts:\n",
    "        camera_position = camera_position.unsqueeze(0)\n",
    "        camera_position = camera_position.to(self.device)\n",
    "        R = look_at_rotation(camera_position, device=self.device)  # (1, 3, 3)\n",
    "        T = -torch.bmm(R.transpose(1, 2), camera_position[:,:,None])[:, :, 0]   # (1, 3)\n",
    "        images = self.renderer(meshes_world=meshes.clone(), R=R, T=T)\n",
    "        fragments = self.renderer.rasterizer(meshes.clone())\n",
    "        \n",
    "        pix_to_face = fragments.pix_to_face\n",
    "        zbuf = fragments.zbuf\n",
    "\n",
    "        v = V[:,F[:,pix_to_face][:,:,:,:,:,0]].squeeze(dim=5).squeeze(dim=1).squeeze(dim=1)\n",
    "        \n",
    "        z_buf_n = torch.square(v - camera_position).sum(dim=-1).unsqueeze(-1)*(pix_to_face >= 0)\n",
    "        zbuf = zbuf*(pix_to_face >= 0)\n",
    "\n",
    "        images = torch.cat([images[:,:,:,0:3], z_buf_n, torch.square(zbuf)], dim=-1)\n",
    "        \n",
    "        images = images.permute(0,3,1,2)\n",
    "        pix_to_face = pix_to_face.permute(0,3,1,2)\n",
    "        \n",
    "        X.append(images.unsqueeze(1))\n",
    "        PF.append(pix_to_face.unsqueeze(1))\n",
    "    \n",
    "    X = torch.cat(X, dim=1)\n",
    "    PF = torch.cat(PF, dim=1)\n",
    "\n",
    "    return X, PF\n",
    "\n",
    "\n",
    "V, F, CN = ds[11]\n",
    "\n",
    "X, PF = render(model, V.unsqueeze(0).cuda(), F.unsqueeze(0).cuda(), CN.unsqueeze(0).cuda())\n",
    "\n",
    "\n",
    "image_data_zbuf_c = X[0,:,3:4].permute(0,2,3,1).squeeze().cpu().numpy()\n",
    "image_data_zbuf = X[0,:,4:].permute(0,2,3,1).squeeze().cpu().numpy()\n",
    "\n",
    "fig = create_figure(image_data_zbuf_c, image_data_zbuf)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
