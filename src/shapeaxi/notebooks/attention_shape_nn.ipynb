{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes, knn_points, knn_gather\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/raid/C1_ML_Analysis/source/ShapeAXI')\n",
    "from shapeaxi import utils\n",
    "from shapeaxi.saxi_layers import TimeDistributed, MHA, Residual, FeedForward, MHA_KNN\n",
    "from shapeaxi.saxi_nets import SaxiMHAEncoder, SaxiMHADecoder, SaxiMHAClassification\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[2m2024-06-17 09:22:37.932 (   0.968s) [         AE48280]    vtkExtractEdges.cxx:435   INFO| \u001b[0mExecuting edge extractor: points are renumbered\u001b[0m\n",
      "\u001b[0m\u001b[2m2024-06-17 09:22:38.087 (   1.123s) [         AE48280]    vtkExtractEdges.cxx:551   INFO| \u001b[0mCreated 491520 edges\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "target_fn = '/mnt/famli_netapp_shared/C1_ML_Analysis/src/diffusion-models/blender/studies/placenta/FAM-025-0499-5/brain/leftWhiteMatter.stl'\n",
    "target = utils.ReadSurf(target_fn)\n",
    "target, target_mean_bb, target_scale_factor = utils.ScaleSurf(target)\n",
    "target_v, target_f, target_e = utils.PolyDataToTensors(target, device=device)\n",
    "target_mesh = Meshes(verts=[target_v], faces=[target_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pointcloud(mesh, title=\"\"):\n",
    "    points = sample_points_from_meshes(mesh, 5000)\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z)])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10242, 2562, 642]\n",
      "[642, 2562, 10242]\n",
      "[10242, 2562, 642]\n"
     ]
    }
   ],
   "source": [
    "sample_levels = []\n",
    "sample_levels_faces = []\n",
    "for l in range(5, 2, -1):\n",
    "    ico_s = utils.IcoSphere(l)\n",
    "    source_v, source_f = utils.PolyDataToTensors_v_f(ico_s)\n",
    "    sample_levels.append(len(source_v))\n",
    "    sample_levels_faces.append(len(source_f))\n",
    "print(sample_levels)\n",
    "print(sample_levels[::-1])\n",
    "print(sample_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SaxiMHAEncoder()\n",
    "model = model.to(device)\n",
    "target_mesh = Meshes(verts=[target_v.cuda()], faces=[target_f.cuda()])\n",
    "\n",
    "X, X_N = sample_points_from_meshes(target_mesh, sample_levels[0], return_normals=True)\n",
    "X = torch.cat([X, X_N], dim=1)\n",
    "target_mesh_encoded = model(X.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "multihead_attn_td = nn.MultiheadAttention(128, 64, bias=False, batch_first=True, dropout=0.1)\n",
    "\n",
    "query = torch.rand(2, 1, 128)\n",
    "key = torch.rand(2, 64, 128)\n",
    "\n",
    "output, attn_output_weights = multihead_attn_td(query, key, key)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHA_KNN(128, 64)(torch.rand(2, 12, 128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select the K closest points to the query\n",
    "batch_size, V_n, Embed_dim = 2, 4, 5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_c = SaxiMHAClassification(input_dim=3, embed_dim=256, num_heads=256, output_dim=32, K=32, sample_levels=[40962, 10242, 2562, 642, 162], dropout=0.1, num_classes=4)\n",
    "mha_c.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_c()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
