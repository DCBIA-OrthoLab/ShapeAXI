{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes, knn_points, knn_gather\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/raid/C1_ML_Analysis/source/ShapeAXI')\n",
    "from shapeaxi import utils\n",
    "from shapeaxi.saxi_layers import TimeDistributed, MHA, Residual, FeedForward, UnpoolMHA, SmoothAttention, SmoothMHA\n",
    "from shapeaxi.saxi_nets import SaxiMHAEncoder, SaxiMHADecoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[2m2024-07-30 14:44:40.098 (   1.016s) [    7F205FC73400]    vtkExtractEdges.cxx:427   INFO| \u001b[0mExecuting edge extractor: points are renumbered\u001b[0m\n",
      "\u001b[0m\u001b[2m2024-07-30 14:44:40.228 (   1.146s) [    7F205FC73400]    vtkExtractEdges.cxx:543   INFO| \u001b[0mCreated 491520 edges\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "target_fn = '/mnt/famli_netapp_shared/C1_ML_Analysis/src/diffusion-models/blender/studies/placenta/FAM-025-0499-5/brain/leftWhiteMatter.stl'\n",
    "target = utils.ReadSurf(target_fn)\n",
    "target, target_mean_bb, target_scale_factor = utils.ScaleSurf(target)\n",
    "target_v, target_f, target_e = utils.PolyDataToTensors(target, device=device)\n",
    "target_mesh = Meshes(verts=[target_v], faces=[target_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pointcloud(mesh, title=\"\"):\n",
    "    points = sample_points_from_meshes(mesh, 5000)\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z)])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10242, 2562, 642]\n",
      "[642, 2562, 10242]\n",
      "[10242, 2562, 642]\n"
     ]
    }
   ],
   "source": [
    "sample_levels = []\n",
    "sample_levels_faces = []\n",
    "for l in range(5, 2, -1):\n",
    "    ico_s = utils.IcoSphere(l)\n",
    "    source_v, source_f = utils.PolyDataToTensors_v_f(ico_s)\n",
    "    sample_levels.append(len(source_v))\n",
    "    sample_levels_faces.append(len(source_f))\n",
    "print(sample_levels)\n",
    "print(sample_levels[::-1])\n",
    "print(sample_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SaxiMHAEncoder()\n",
    "model = model.to(device)\n",
    "target_mesh = Meshes(verts=[target_v.cuda()], faces=[target_f.cuda()])\n",
    "\n",
    "X, X_N = sample_points_from_meshes(target_mesh, sample_levels[0], return_normals=True)\n",
    "X = torch.cat([X, X_N], dim=1)\n",
    "target_mesh_encoded, _ = model(X.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder = SaxiMHADecoder(input_dim=256)\n",
    "decoder = decoder.cuda()\n",
    "X_hat = decoder(target_mesh_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([163842, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mesh.verts_padded().shape\n",
    "target_mesh.verts_list()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def saxi_point_triangle_distance(X, X_hat, K_triangle=1, ignore_first=False, randomize=False):\n",
    "    \"\"\"\n",
    "    Compute the distance between a point and the nearest triangle.\n",
    "    It uses the knn_points and knn_gather functions from PyTorch3D to find the nearest triangle.\n",
    "    Args:\n",
    "        X: (B, N0, 3) tensor of points\n",
    "        X_hat: (B, N1, 3) tensor of points\"\"\"\n",
    "    \n",
    "    k_ignore = 0\n",
    "    if ignore_first:\n",
    "        k_ignore = 1\n",
    "\n",
    "    dists = knn_points(X_hat, X, K=(3*K_triangle + k_ignore))\n",
    "    start_idx = (3*(K_triangle-1)) + k_ignore\n",
    "\n",
    "    if randomize:\n",
    "        idx = dists.idx[:, :, torch.randperm(dists.idx.shape[2])]\n",
    "    else:\n",
    "        idx = dists.idx\n",
    "    \n",
    "    x = knn_gather(X, idx[:, :, start_idx:start_idx + 3])\n",
    "    # Compute the normal of the triangle\n",
    "    \n",
    "    N = torch.cross(x[:, :, 1] - x[:, :, 0], x[:, :, 2] - x[:, :, 0], dim=-1)\n",
    "    N = N / torch.norm(N, dim=1, keepdim=True)\n",
    "    # Compute the vector from the point to the first vertex of the triangle\n",
    "    X_v = (X_hat - x[:, :, 0]) \n",
    "    \n",
    "    return torch.sum(torch.abs(torch.einsum('ijk,ijk->ij', X_v, N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1549, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saxi_point_triangle_distance(target_v.unsqueeze(0), X_hat, K_triangle=3, randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0311, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saxi_point_triangle_distance(target_v.unsqueeze(0), X_hat, ignore_first=True, K_triangle=3, randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[16., 17., 18., 19.],\n",
       "          [20., 21., 22., 23.],\n",
       "          [24., 25., 26., 27.],\n",
       "          [28., 29., 30., 31.]],\n",
       "\n",
       "         [[32., 33., 34., 35.],\n",
       "          [36., 37., 38., 39.],\n",
       "          [40., 41., 42., 43.],\n",
       "          [44., 45., 46., 47.]]],\n",
       "\n",
       "\n",
       "        [[[48., 49., 50., 51.],\n",
       "          [52., 53., 54., 55.],\n",
       "          [56., 57., 58., 59.],\n",
       "          [60., 61., 62., 63.]],\n",
       "\n",
       "         [[64., 65., 66., 67.],\n",
       "          [68., 69., 70., 71.],\n",
       "          [72., 73., 74., 75.],\n",
       "          [76., 77., 78., 79.]],\n",
       "\n",
       "         [[80., 81., 82., 83.],\n",
       "          [84., 85., 86., 87.],\n",
       "          [88., 89., 90., 91.],\n",
       "          [92., 93., 94., 95.]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = np.array([2, 3, 4, 4])\n",
    "\n",
    "test_v = torch.range(start=0, end=np.prod(size) - 1).reshape(size.tolist())\n",
    "test_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23.],\n",
       "         [24., 25., 26., 27.],\n",
       "         [28., 29., 30., 31.],\n",
       "         [32., 33., 34., 35.],\n",
       "         [36., 37., 38., 39.],\n",
       "         [40., 41., 42., 43.],\n",
       "         [44., 45., 46., 47.]],\n",
       "\n",
       "        [[48., 49., 50., 51.],\n",
       "         [52., 53., 54., 55.],\n",
       "         [56., 57., 58., 59.],\n",
       "         [60., 61., 62., 63.],\n",
       "         [64., 65., 66., 67.],\n",
       "         [68., 69., 70., 71.],\n",
       "         [72., 73., 74., 75.],\n",
       "         [76., 77., 78., 79.],\n",
       "         [80., 81., 82., 83.],\n",
       "         [84., 85., 86., 87.],\n",
       "         [88., 89., 90., 91.],\n",
       "         [92., 93., 94., 95.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_v.view(test_v.shape[0], -1, test_v.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1000, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shapeaxi.saxi_layers import SelfAttention\n",
    "\n",
    "# Example shapes\n",
    "BS = 2  # Batch size\n",
    "V_n = 1000  # Some dimension\n",
    "K = 4  # Number of neighbors\n",
    "embed_dim = 128  # Embedding dimension\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, pooling_factor=0.5, embed_dim=128, hidden_dim=64, K=4):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.pooling_factor = pooling_factor\n",
    "        self.embed_dim = embed_dim\n",
    "        self.attn = SelfAttention(embed_dim, hidden_dim, dim=2)\n",
    "        self.K = K\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # find closest points to self, i.e., each point in the sample finds the closest K points in the sample\n",
    "        dists = knn_points(x, x, K=self.K)\n",
    "        # gather the K closest points\n",
    "        \n",
    "        x = knn_gather(x, dists.idx)\n",
    "        # apply self attention, i.e., weighted average of the K closest points\n",
    "        x, x_s = self.attn(x, x)\n",
    "        x_s = x_s[:,:,0,:]\n",
    "\n",
    "        n_samples = int(x.shape[1]*self.pooling_factor)\n",
    "        idx = torch.argsort(x_s, descending=True, dim=1)[:,:n_samples]\n",
    "        \n",
    "        x = knn_gather(x, idx).squeeze(2)\n",
    "        x_s = knn_gather(x_s, idx).squeeze(2)\n",
    "        \n",
    "        return x, x_s\n",
    "\n",
    "x = torch.rand(BS, V_n, embed_dim)\n",
    "AttentionPooling(pooling_factor=0.25)(x)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
