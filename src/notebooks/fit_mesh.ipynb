{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/raid/C1_ML_Analysis/source/ShapeAXI')\n",
    "from shapeaxi import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fn = '/mnt/famli_netapp_shared/C1_ML_Analysis/src/diffusion-models/blender/studies/placenta/FAM-025-0499-5/brain/leftWhiteMatter.stl'\n",
    "target = utils.ReadSurf(target_fn)\n",
    "target, target_mean_bb, target_scale_factor = utils.ScaleSurf(target)\n",
    "target_v, target_f, target_e = utils.PolyDataToTensors(target, device=device)\n",
    "target_mesh = Meshes(verts=[target_v], faces=[target_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pointcloud(mesh, title=\"\"):\n",
    "    points = sample_points_from_meshes(mesh, 5000)\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z)])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pointcloud(target_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = utils.IcoSphere(6)\n",
    "source_v, source_f, source_e = utils.PolyDataToTensors(source, device=device)\n",
    "source_mesh = Meshes(verts=[source_v], faces=[source_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pointcloud(source_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deform_verts = torch.full(source_mesh.verts_packed().shape, 0.0, device=device, requires_grad=True)\n",
    "optimizer = torch.optim.SGD([deform_verts], lr=1.0, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPoints = source_v.shape[0]\n",
    "# Number of optimization steps\n",
    "Niter = 20000\n",
    "# Weight for the chamfer loss\n",
    "w_chamfer = 1.0 \n",
    "# Weight for mesh edge loss\n",
    "w_edge = 1.0 \n",
    "# Weight for mesh normal consistency\n",
    "w_normal = 0.01 \n",
    "# Weight for mesh laplacian smoothing\n",
    "w_laplacian = 0.1 \n",
    "# Plot period for the losses\n",
    "plot_period = 250\n",
    "loop = tqdm(range(Niter))\n",
    "\n",
    "chamfer_losses = []\n",
    "laplacian_losses = []\n",
    "edge_losses = []\n",
    "normal_losses = []\n",
    "\n",
    "for i in loop:\n",
    "    # Initialize optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Deform the mesh\n",
    "    new_source_mesh = source_mesh.offset_verts(deform_verts)\n",
    "    \n",
    "    # We sample 5k points from the surface of each mesh \n",
    "    sample_target = sample_points_from_meshes(target_mesh, NPoints)\n",
    "    # sample_source = sample_points_from_meshes(new_source_mesh, NPoints)\n",
    "    \n",
    "    # We compare the two sets of pointclouds by computing (a) the chamfer loss\n",
    "    loss_chamfer, _ = chamfer_distance(sample_target, new_source_mesh.verts_packed().unsqueeze(0))\n",
    "    \n",
    "    # and (b) the edge length of the predicted mesh\n",
    "    loss_edge = mesh_edge_loss(new_source_mesh)\n",
    "    \n",
    "    # mesh normal consistency\n",
    "    loss_normal = mesh_normal_consistency(new_source_mesh)\n",
    "    \n",
    "    # mesh laplacian smoothing\n",
    "    loss_laplacian = mesh_laplacian_smoothing(new_source_mesh, method=\"uniform\")\n",
    "    \n",
    "    # Weighted sum of the losses\n",
    "    loss = loss_chamfer * w_chamfer + loss_edge * w_edge + loss_normal * w_normal + loss_laplacian * w_laplacian\n",
    "    \n",
    "    # Print the losses\n",
    "    loop.set_description('total_loss = %.6f' % loss)\n",
    "    \n",
    "    # Save the losses for plotting\n",
    "    chamfer_losses.append(float(loss_chamfer.detach().cpu()))\n",
    "    edge_losses.append(float(loss_edge.detach().cpu()))\n",
    "    normal_losses.append(float(loss_normal.detach().cpu()))\n",
    "    laplacian_losses.append(float(loss_laplacian.detach().cpu()))\n",
    "        \n",
    "    # Optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"chamfer\": chamfer_losses,\n",
    "    \"edge\": edge_losses,\n",
    "    \"normal\": normal_losses,\n",
    "    \"laplacian\": laplacian_losses,\n",
    "})\n",
    "px.line(df, title=\"Losses\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_mean_bb, target_scale_factor\n",
    "\n",
    "new_source_mesh_v = (new_source_mesh.verts_packed().detach().cpu())/target_scale_factor + target_mean_bb\n",
    "\n",
    "new_source_mesh_surf = utils.TensorToPolyData(new_source_mesh_v, new_source_mesh.faces_packed().detach().cpu())\n",
    "utils.WriteSurf(new_source_mesh_surf, '/mnt/famli_netapp_shared/C1_ML_Analysis/leftWhiteMatter_fitted.stl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mount_point = \"/mnt/raid/C1_ML_Analysis\"\n",
    "df = pd.read_csv(os.path.join(mount_point, \"simulated_data_export/rest_meshes_vtk.csv\"))\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
